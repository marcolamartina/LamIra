{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Intent_classification_training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPQsFszMynqCAf2z2uqLk3J"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWnqGhiBBQVU","executionInfo":{"status":"ok","timestamp":1615548057453,"user_tz":-60,"elapsed":11648,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"1421f431-7e6b-44e9-9358-2e34ff267a2c"},"source":["!pip install transformers==3\r\n","!pip install tensorflow-gpu\r\n","import numpy as np # linear algebra\r\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n","import json\r\n","import os\r\n","from sklearn.metrics import roc_curve\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.metrics import f1_score\r\n","from sklearn.model_selection import train_test_split\r\n","import torch\r\n","import torch.nn as nn\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.metrics import classification_report\r\n","import transformers\r\n","from transformers import BertModel, BertTokenizer\r\n","import warnings\r\n","warnings.filterwarnings('ignore')\r\n","# specify GPU\r\n","device = torch.device(\"cuda\")\r\n","print(device)\r\n","# Chose Language\r\n","language=\"it-IT\"\r\n","berts={\"it-IT\":\"bert-base-multilingual-cased\", \"en-US\":\"bert-base-uncased\"}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.95)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.43)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.4.1)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.32.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.10.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.1)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (54.0.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.27.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.4)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.1)\n","cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_8us2LgBTjy","executionInfo":{"status":"ok","timestamp":1615548057454,"user_tz":-60,"elapsed":11631,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"432f474c-42ff-414a-9f0b-f729b7ae2ee5"},"source":["from google.colab import drive\r\n","drive.mount(\"/content/drive/\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O5Cdjgo-G-e7"},"source":["data_dir = \"/content/drive/My Drive/Tesi/Code/Intent_Classification\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-SWfvwOBdUC"},"source":["class LoadingData():\r\n","            \r\n","    def __init__(self):\r\n","        #Davide=\"Ingegneria/Magistrale/Tesi/\"\r\n","        train_file_path = os.path.join(data_dir,\"Dataset\",\"Train\")\r\n","        validation_file_path = os.path.join(data_dir,\"Dataset\",\"Validate\")\r\n","        category_id = 0\r\n","        self.cat_to_intent = {}\r\n","        self.intent_to_cat = {}\r\n","        for dirname, _, filenames in os.walk(train_file_path):\r\n","            for filename in filenames:\r\n","                \r\n","                file_path = os.path.join(dirname, filename)\r\n","                intent_id = filename.replace(\".txt\",\"\")\r\n","                self.cat_to_intent[category_id] = intent_id\r\n","                self.intent_to_cat[intent_id] = category_id\r\n","                category_id+=1\r\n","        '''Training data'''\r\n","        self.train_data_frame = self.file_to_dataframe(train_file_path)  \r\n","        self.train_data_frame = self.train_data_frame.sample(frac = 1)\r\n","        \r\n","        '''Validation data''' \r\n","        self.validation_data_frame = self.file_to_dataframe(validation_file_path)   \r\n","        self.validation_data_frame = self.validation_data_frame.sample(frac = 1)\r\n","\r\n","    def file_to_dataframe(self,file_path,file_path_2=None):\r\n","          data = list() \r\n","          for dirname, _, filenames in os.walk(file_path):\r\n","              for filename in filenames:\r\n","                  file_path = os.path.join(dirname, filename)\r\n","                  intent_id = filename.replace(\".txt\",\"\")\r\n","                  data+=self.make_data_for_intent_from_txt(file_path,intent_id,self.intent_to_cat[intent_id])\r\n","          if file_path_2!=None:\r\n","              for dirname, _, filenames in os.walk(file_path_2):\r\n","                  for filename in filenames:\r\n","                      file_path_2 = os.path.join(dirname, filename)\r\n","                      intent_id = filename.replace(\".txt\",\"\")\r\n","                      data+=self.make_data_for_intent_from_txt(file_path_2,intent_id,self.intent_to_cat[intent_id])      \r\n","          return pd.DataFrame(data, columns =['query', 'intent','category'])  \r\n","        \r\n","        \r\n","    def make_data_for_intent_from_txt(self,txt_file,intent_id,cat):\r\n","        query_list=[]\r\n","        with open(txt_file, 'r') as f:\r\n","            for line in f.readlines():\r\n","                text=line.replace(\"\\n\", \"\")\r\n","                query_list.append((text,intent_id,cat))\r\n","        return query_list "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIxs5iQvBd_X"},"source":["ld = LoadingData()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxTFA_JbBgJH"},"source":["train_df = ld.train_data_frame"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rk9a8KyxBhcv"},"source":["label_map,id2label = ld.intent_to_cat,ld.cat_to_intent"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cL4XkA_BhZU"},"source":["train_text, val_text, train_labels, val_labels = train_test_split(train_df['query'], train_df['category'], \r\n","                                                                    random_state=2018, \r\n","                                                                    test_size=0.2, \r\n","                                                                    stratify=train_df['category'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g78suUciBhW4"},"source":["# Load the BERT tokenizer\r\n","tokenizer = BertTokenizer.from_pretrained(berts[language])\r\n","bert = BertModel.from_pretrained(berts[language])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"mzEYB73oBhUf","executionInfo":{"status":"ok","timestamp":1615548083264,"user_tz":-60,"elapsed":37383,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"0ac47dc7-1952-42cc-bf05-5bfa6d0f8abd"},"source":["seq_len = [len(i.split()) for i in train_text]\r\n","\r\n","pd.Series(seq_len).hist(bins = 30)\r\n","max_seq_len = max(seq_len)\r\n","print(max_seq_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["9\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAT4klEQVR4nO3df4zc9Z3f8efrcHIB9g6TkFtRm9aoh2gpbu/winKljXbD3ZWEKKAqikA0BxGVeyqXcheqhKR/oP4Rlajl0hxtI/liiqP42HCEyBSSFMSxRyMVrjbhYn4kF5c4HC6xExmc2wQ1IX33j/1usrXHeGdmd2f48HxIq53vj5nPa0Zfv/zdz35nNlWFJKktPzfqAJKklWe5S1KDLHdJapDlLkkNstwlqUHrRh0A4IwzzqhNmzYNdN8f/OAHnHrqqSsbaAWMay4Y32zm6o+5+tNirj179nyvqt7ac2NVjfxry5YtNaiHH3544PuupnHNVTW+2czVH3P1p8VcwO46Tq86LSNJDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ0ai48fGMbeA0e49qb7l7Xv/lsuW+U0kjQeTnjmnuT2JIeSPNlj241JKskZ3XKS/EGSfUm+luSC1QgtSXp1y5mWuQO49OiVSc4CfhN4bsnqdwDndF9bgU8NH1GS1K8TlntVPQIc7rHpE8CHgKV/hPVy4DPdZ9o8CqxPcuaKJJUkLVtqGX8gO8km4L6qOr9bvhx4e1XdkGQ/MFVV30tyH3BLVX2l2+8h4MNVtbvHY25l4eyeycnJLbOzswM9gUOHj3Dw5eXtu3nDaQONMYj5+XkmJibWbLx+jGs2c/XHXP1pMdfMzMyeqprqta3vX6gmOQX4KAtTMgOrqm3ANoCpqamanp4e6HFu27mLW/cu72nsv3qwMQYxNzfHoM9ptY1rNnP1x1z9eb3lGuRqmb8JnA38eRKAjcDjSS4EDgBnLdl3Y7dOkrSG+r7Ovar2VtUvVdWmqtoEPA9cUFXfAe4Ffqu7auYi4EhVvbCykSVJJ7KcSyHvBP4HcG6S55Nc9yq7fxF4FtgH/CHwL1YkpSSpLyeclqmqq06wfdOS2wVcP3wsSdIw/PgBSWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ16ITlnuT2JIeSPLlk3b9L8vUkX0vyhSTrl2z7SJJ9Sb6R5B+vVnBJ0vEt58z9DuDSo9Y9CJxfVX8X+AvgIwBJzgOuBP5Od5//nOSkFUsrSVqWE5Z7VT0CHD5q3QNV9Uq3+Ciwsbt9OTBbVf+nqr4F7AMuXMG8kqRlSFWdeKdkE3BfVZ3fY9t/BT5XVZ9N8h+BR6vqs9227cCXquruHvfbCmwFmJyc3DI7OzvQEzh0+AgHX17evps3nDbQGIOYn59nYmJizcbrx7hmM1d/zNWfFnPNzMzsqaqpXtvWDRMqyb8GXgF29nvfqtoGbAOYmpqq6enpgTLctnMXt+5d3tPYf/VgYwxibm6OQZ/TahvXbObqj7n683rLNXC5J7kWeBdwSf3s9P8AcNaS3TZ26yRJa2igSyGTXAp8CHh3Vf1wyaZ7gSuT/HySs4FzgD8bPqYkqR8nPHNPcicwDZyR5HngZhaujvl54MEksDDP/ttV9VSSu4CnWZiuub6qfrJa4SVJvZ2w3Kvqqh6rt7/K/h8DPjZMKEnScHyHqiQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGnTCck9ye5JDSZ5csu7NSR5M8s3u++nd+iT5gyT7knwtyQWrGV6S1NtyztzvAC49at1NwENVdQ7wULcM8A7gnO5rK/CplYkpSerHCcu9qh4BDh+1+nJgR3d7B3DFkvWfqQWPAuuTnLlSYSVJy5OqOvFOySbgvqo6v1t+qarWd7cDvFhV65PcB9xSVV/ptj0EfLiqdvd4zK0snN0zOTm5ZXZ2dqAncOjwEQ6+vLx9N284baAxBjE/P8/ExMSajdePcc1mrv6Yqz8t5pqZmdlTVVO9tq0bKhVQVZXkxP9DHHu/bcA2gKmpqZqenh5o/Nt27uLWvct7GvuvHmyMQczNzTHoc1pt45rNXP0xV39eb7kGvVrm4OJ0S/f9ULf+AHDWkv02duskSWto0HK/F7imu30NsGvJ+t/qrpq5CDhSVS8MmVGS1KcTzmckuROYBs5I8jxwM3ALcFeS64BvA+/tdv8i8E5gH/BD4P2rkFmSdAInLPequuo4my7psW8B1w8bSpI0HN+hKkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBg1V7kl+L8lTSZ5McmeSNyU5O8ljSfYl+VySN65UWEnS8gxc7kk2AP8SmKqq84GTgCuBjwOfqKpfBl4ErluJoJKk5Rt2WmYdcHKSdcApwAvA24G7u+07gCuGHEOS1KdU1eB3Tm4APga8DDwA3AA82p21k+Qs4Evdmf3R990KbAWYnJzcMjs7O1CGQ4ePcPDl5e27ecNpA40xiPn5eSYmJtZsvH6MazZz9cdc/Wkx18zMzJ6qmuq1bd2ggZKcDlwOnA28BPwxcOly719V24BtAFNTUzU9PT1Qjtt27uLWvct7GvuvHmyMQczNzTHoc1pt45rNXP0xV39eb7mGmZb5deBbVfXdqvoxcA9wMbC+m6YB2AgcGDKjJKlPw5T7c8BFSU5JEuAS4GngYeA93T7XALuGiyhJ6tfA5V5Vj7Hwi9PHgb3dY20DPgx8MMk+4C3A9hXIKUnqw8Bz7gBVdTNw81GrnwUuHOZxJUnD8R2qktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGDfXHOqTXg70HjnDtTfefcL/9t1y2Bmmk5fHMXZIaZLlLUoMsd0lq0FDlnmR9kruTfD3JM0l+LcmbkzyY5Jvd99NXKqwkaXmGPXP/JPDlqvpbwN8DngFuAh6qqnOAh7plSdIaGrjck5wGvA3YDlBVP6qql4DLgR3dbjuAK4YNKUnqT6pqsDsmvwJsA55m4ax9D3ADcKCq1nf7BHhxcfmo+28FtgJMTk5umZ2dHSjHocNHOPjy8vbdvOG0gcYYxPz8PBMTE2s2Xi97DxzpuX7yZI55zdbytVlqacZeuRaNKh8s/xhb64zjcIz1Yq7+DJNrZmZmT1VN9do2TLlPAY8CF1fVY0k+CXwf+MDSMk/yYlW96rz71NRU7d69e6Act+3cxa17l3e5/lpehzw3N8f09PSajdfLpuNcm33j5leOec1GdY320oy9ci0a5TXkyz3G1jrjOBxjvZirP8PkSnLcch9mzv154Pmqeqxbvhu4ADiY5Mxu4DOBQ0OMIUkawMDlXlXfAf4yybndqktYmKK5F7imW3cNsGuohJKkvg378QMfAHYmeSPwLPB+Fv7DuCvJdcC3gfcOOYYkqU9DlXtVPQH0mu+5ZJjHlSQNx3eoSlKDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQUOXe5KTknw1yX3d8tlJHkuyL8nnkrxx+JiSpH6sxJn7DcAzS5Y/Dnyiqn4ZeBG4bgXGkCT1YahyT7IRuAz4dLcc4O3A3d0uO4ArhhlDktS/VNXgd07uBv4t8AvAvwKuBR7tztpJchbwpao6v8d9twJbASYnJ7fMzs4OlOHQ4SMcfHl5+27ecNpAYwxifn6eiYmJNRuvl70HjvRcP3kyx7xma/naLLU0Y69ci0aVD5Z/jK11xnE4xnoxV3+GyTUzM7OnqqZ6bVs3aKAk7wIOVdWeJNP93r+qtgHbAKampmp6uu+HAOC2nbu4de/ynsb+qwcbYxBzc3MM+pxWyrU33d9z/Y2bXznmNVvL12appRl75Vo0qnyw/GNsrTOOwzHWi7n6s1q5Bi534GLg3UneCbwJ+EXgk8D6JOuq6hVgI3Bg+JiSpH4MPOdeVR+pqo1VtQm4EviTqroaeBh4T7fbNcCuoVNKkvqyGte5fxj4YJJ9wFuA7aswhiTpVQwzLfNTVTUHzHW3nwUuXInHlSQNxneoSlKDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoNW5C8xSVp5m266/1W337j5Fa696X7233LZGiU6Vq+Mi7mWGmXG1yvLfQiv9o9v6QHugS1prTktI0kNGrjck5yV5OEkTyd5KskN3fo3J3kwyTe776evXFxJ0nIMc+b+CnBjVZ0HXARcn+Q84Cbgoao6B3ioW5YkraGBy72qXqiqx7vbfwU8A2wALgd2dLvtAK4YNqQkqT+pquEfJNkEPAKcDzxXVeu79QFeXFw+6j5bga0Ak5OTW2ZnZwca+9DhIxx8eXn7bt5w2kBjHM/eA0eOu23yZH6aa6XHXa7j5VuabdE4ZOyVa9Go8sHyj7G1PL7gZ6/XKF+bXhnH6fhaan5+nomJiVHHOMYwuWZmZvZU1VSvbUOXe5IJ4E+Bj1XVPUleWlrmSV6sqledd5+amqrdu3cPNP5tO3dx697lXfSz0letnOhqmcVco7pa5nj5lmZbNA4Ze+VaNMorjpZ7jK3l8QU/e73G8VLIcTm+lpqbm2N6enrUMY4xTK4kxy33oa6WSfIG4PPAzqq6p1t9MMmZ3fYzgUPDjCFJ6t8wV8sE2A48U1W/v2TTvcA13e1rgF2Dx5MkDWKYNzFdDLwP2JvkiW7dR4FbgLuSXAd8G3jvcBElSf0auNyr6itAjrP5kkEfV5I0PN+hKkkNstwlqUGWuyQ1yHKXpAZZ7pLUID/PXZJWwYneYbzojktPXZXxPXOXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CA/fkBSs47+A+zXHucjAcbhD3ivNM/cJalBlrskNchyl6QGrVq5J7k0yTeS7Ety02qNI0k61qqUe5KTgP8EvAM4D7gqyXmrMZYk6VirdeZ+IbCvqp6tqh8Bs8DlqzSWJOkoqaqVf9DkPcClVfXPuuX3AX+/qn5nyT5bga3d4rnANwYc7gzge0PEXS3jmgvGN5u5+mOu/rSY629U1Vt7bRjZde5VtQ3YNuzjJNldVVMrEGlFjWsuGN9s5uqPufrzesu1WtMyB4Czlixv7NZJktbAapX7/wTOSXJ2kjcCVwL3rtJYkqSjrMq0TFW9kuR3gP8GnATcXlVPrcZYrMDUzioZ11wwvtnM1R9z9ed1lWtVfqEqSRot36EqSQ2y3CWpQa/Zck9ye5JDSZ4cdZalkpyV5OEkTyd5KskNo84EkORNSf4syZ93uf7NqDMtleSkJF9Nct+osyxKsj/J3iRPJNk96jyLkqxPcneSryd5JsmvjUGmc7vXafHr+0l+d9S5AJL8XnfMP5nkziRvGnUmgCQ3dJmeWo3X6jU7557kbcA88JmqOn/UeRYlORM4s6oeT/ILwB7giqp6esS5ApxaVfNJ3gB8Bbihqh4dZa5FST4ITAG/WFXvGnUeWCh3YKqqxuqNL0l2AP+9qj7dXY12SlW9NOpci7qPHznAwhsXvz3iLBtYONbPq6qXk9wFfLGq7hhxrvNZeOf+hcCPgC8Dv11V+1ZqjNfsmXtVPQIcHnWOo1XVC1X1eHf7r4BngA2jTQW1YL5bfEP3NRb/syfZCFwGfHrUWcZdktOAtwHbAarqR+NU7J1LgP816mJfYh1wcpJ1wCnA/x5xHoC/DTxWVT+sqleAPwX+yUoO8Jot99eCJJuAXwUeG22SBd3UxxPAIeDBqhqLXMB/AD4E/N9RBzlKAQ8k2dN9XMY4OBv4LvBfummsTyc5ddShjnIlcOeoQwBU1QHg3wPPAS8AR6rqgdGmAuBJ4B8leUuSU4B38v+/8XNolvsqSTIBfB743ar6/qjzAFTVT6rqV1h4x/CF3Y+GI5XkXcChqtoz6iw9/MOquoCFTze9vpsKHLV1wAXAp6rqV4EfAGPzkdrdNNG7gT8edRaAJKez8KGFZwN/DTg1yT8dbSqoqmeAjwMPsDAl8wTwk5Ucw3JfBd2c9ueBnVV1z6jzHK37Mf5h4NJRZwEuBt7dzW/PAm9P8tnRRlrQnfVRVYeAL7AwPzpqzwPPL/mp624Wyn5cvAN4vKoOjjpI59eBb1XVd6vqx8A9wD8YcSYAqmp7VW2pqrcBLwJ/sZKPb7mvsO4Xl9uBZ6rq90edZ1GStyZZ390+GfgN4OujTQVV9ZGq2lhVm1j4cf5PqmrkZ1ZJTu1+IU437fGbLPwoPVJV9R3gL5Oc2626BBjpL+uPchVjMiXTeQ64KMkp3b/NS1j4PdjIJfml7vtfZ2G+/Y9W8vFH9qmQw0pyJzANnJHkeeDmqto+2lTAwpno+4C93fw2wEer6osjzARwJrCju5Lh54C7qmpsLjscQ5PAFxb6gHXAH1XVl0cb6ac+AOzspkCeBd4/4jzAT/8T/A3gn486y6KqeizJ3cDjwCvAVxmfjyH4fJK3AD8Grl/pX4y/Zi+FlCQdn9MyktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ16P8BZRMs0QKFeWgAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"uTyXVES6BhJk"},"source":["# tokenize and encode sequences in the training set\r\n","if max_seq_len>512:\r\n","    max_seq_len = 512\r\n","tokens_train = tokenizer.batch_encode_plus(\r\n","    train_text.tolist(),\r\n","    max_length = max_seq_len,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False\r\n",")\r\n","\r\n","# tokenize and encode sequences in the validation set\r\n","tokens_val = tokenizer.batch_encode_plus(\r\n","    val_text.tolist(),\r\n","    max_length = max_seq_len,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False\r\n",")\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7R39qEBBhE1","executionInfo":{"status":"ok","timestamp":1615548083266,"user_tz":-60,"elapsed":37366,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"6f90b6ad-98a7-44de-a8c1-9b298e1e1f17"},"source":["# for train set\r\n","train_seq = torch.tensor(tokens_train['input_ids'])\r\n","train_mask = torch.tensor(tokens_train['attention_mask'])\r\n","train_y = torch.tensor(train_labels.tolist())\r\n","print(\"train_y:\",train_y)\r\n","# for validation set\r\n","val_seq = torch.tensor(tokens_val['input_ids'])\r\n","val_mask = torch.tensor(tokens_val['attention_mask'])\r\n","val_y = torch.tensor(val_labels.tolist())\r\n","print(\"val_y:\",val_y)\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_y: tensor([1, 1, 3, 2, 2, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 0, 2, 0, 1, 2, 1, 3, 0, 0,\n","        2, 0, 2, 1, 2, 1, 1, 0, 0, 3, 3, 0, 3, 2, 3, 1, 2, 0, 2, 1, 0, 0, 3, 0,\n","        0, 2, 2, 0, 3, 3, 1, 0, 2, 1, 0, 2, 0, 1, 3, 0, 0, 3, 1, 3, 1, 3, 2, 1,\n","        0, 3, 0, 3, 3, 2, 3, 1, 1, 1, 0, 3, 3, 3, 1, 0, 2, 2, 0, 1, 1, 1, 2, 2,\n","        0, 0, 0, 1, 2, 0, 1, 2, 3, 2, 0, 0, 1, 3, 3, 1, 1, 3, 1, 2, 2, 0, 3, 3,\n","        1, 2, 2, 1, 1, 0, 2, 2, 0, 0, 3, 1, 0, 0, 1, 1, 0, 2, 0, 3, 1, 0, 1, 1,\n","        1, 3, 0, 0, 0, 0, 1, 1, 3, 2, 1, 3, 3, 2, 2, 1, 1, 2, 1, 0, 1, 0, 3, 0,\n","        2, 3, 3, 0, 3, 1, 3, 0, 3, 1, 3, 0, 0, 1, 0, 3, 0, 2, 2, 0, 1, 0, 1, 0,\n","        0, 2, 3, 3, 3, 2, 0, 1, 1, 0, 2, 0, 1, 2, 0, 3, 0, 3, 2, 0, 3, 2, 2, 2,\n","        3, 0, 3, 2, 3, 0, 0, 3, 1, 2, 1, 3, 3, 2, 0, 3, 2, 3, 3, 3, 2, 1, 3, 2,\n","        1, 3, 0, 3, 1, 3, 0, 3, 2, 1, 0, 3, 0, 0, 0, 3, 2, 0, 1, 3, 0, 3, 1, 0,\n","        0, 0, 0, 2, 0, 0, 2, 1, 0, 1, 1, 3, 2, 3, 2, 2, 1, 1, 2, 1, 1, 2, 3, 3,\n","        3, 0, 1, 3, 3, 3, 2, 0, 1, 1, 3, 3, 0, 1, 2, 0, 1, 1, 1, 2, 0, 0, 0, 0,\n","        0, 1, 2, 0, 1, 3, 0, 2, 2, 0, 3, 2, 2, 3, 0, 3, 2, 3, 3, 3, 3, 1, 0, 1,\n","        0, 0, 1, 0, 0, 3, 1, 0, 0, 1, 3, 0, 2, 2, 3, 2, 2, 0, 3, 0, 0, 1, 1, 0,\n","        2, 2, 2, 2, 0, 1, 2, 2, 1, 3, 2, 0, 1, 3, 1, 2, 0, 0, 3, 3, 3, 3, 1, 2,\n","        1, 0, 3, 1, 2, 0, 3, 3, 2, 3, 3, 0, 3, 3, 2, 3, 1, 0, 0, 1, 2, 2, 0, 2,\n","        2, 2, 3, 2, 0, 1, 1, 0])\n","val_y: tensor([3, 3, 2, 1, 0, 1, 0, 2, 3, 3, 0, 2, 2, 1, 0, 1, 0, 3, 1, 3, 0, 3, 2, 1,\n","        1, 2, 1, 0, 3, 0, 0, 3, 2, 3, 3, 3, 0, 3, 3, 2, 2, 0, 2, 3, 0, 1, 2, 0,\n","        1, 3, 1, 0, 1, 0, 3, 0, 0, 1, 0, 1, 1, 0, 0, 0, 3, 3, 2, 1, 0, 3, 2, 0,\n","        2, 1, 1, 3, 2, 3, 2, 3, 2, 1, 3, 1, 1, 2, 0, 2, 2, 2, 3, 2, 0, 0, 1, 1,\n","        2, 2, 1, 0, 0, 3, 0, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PLkncx1iBnp6"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n","\r\n","#define a batch size\r\n","batch_size = 16\r\n","\r\n","# wrap tensors\r\n","train_data = TensorDataset(train_seq, train_mask, train_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","train_sampler = RandomSampler(train_data)\r\n","\r\n","# dataLoader for train set\r\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","val_data = TensorDataset(val_seq, val_mask, val_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","val_sampler = SequentialSampler(val_data)\r\n","\r\n","# dataLoader for validation set\r\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpyZQOzzBnn3"},"source":["# freeze all the parameters\r\n","for param in bert.parameters():\r\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWmRKqgvBnlj"},"source":["class BERT_Arch(nn.Module):\r\n","    def __init__(self, bert,label_map):\r\n","        super(BERT_Arch, self).__init__()\r\n","        self.bert = bert \r\n","      \r\n","        # dropout layer\r\n","        self.dropout = nn.Dropout(0.1)\r\n","\r\n","        # relu activation function\r\n","        self.relu =  nn.ReLU()\r\n","\r\n","        # dense layer 1\r\n","        self.fc1 = nn.Linear(768,512)\r\n","\r\n","        # dense layer 2 (Output layer)\r\n","        self.fc2 = nn.Linear(512,len(label_map))\r\n","\r\n","        #softmax activation function\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    #define the forward pass\r\n","    def forward(self, sent_id, mask):\r\n","\r\n","        #pass the inputs to the model  \r\n","        _, cls_hs = self.bert(sent_id, attention_mask=mask)\r\n","\r\n","        x = self.fc1(cls_hs)\r\n","\r\n","        x = self.relu(x)\r\n","\r\n","        x = self.dropout(x)\r\n","\r\n","        # output layer\r\n","        x = self.fc2(x)\r\n","\r\n","        # apply softmax activation\r\n","        x = self.softmax(x)\r\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1v_PNGIRBnh2"},"source":["# pass the pre-trained BERT to our define architecture\r\n","model = BERT_Arch(bert,label_map)\r\n","\r\n","# push the model to GPU\r\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4DlMLanBngB"},"source":["# optimizer from hugging face transformers\r\n","from transformers import AdamW\r\n","\r\n","# define the optimizer\r\n","optimizer = AdamW(model.parameters(), lr = 1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6XD6vwPBnd-","executionInfo":{"status":"ok","timestamp":1615548085726,"user_tz":-60,"elapsed":39788,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"227247dc-ac1c-439f-df5e-84913e2cf73f"},"source":["from sklearn.utils.class_weight import compute_class_weight\r\n","\r\n","#compute the class weights\r\n","class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\r\n","\r\n","print(class_wts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0.86666667 1.08333333 1.08333333 1.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hCiLm-0jBnb6"},"source":["# convert class weights to tensor\r\n","weights= torch.tensor(class_wts,dtype=torch.float)\r\n","weights = weights.to(device)\r\n","\r\n","# loss function\r\n","cross_entropy  = nn.NLLLoss(weight=weights) \r\n","\r\n","# number of training epochs\r\n","epochs = 50"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R2ZKd7TMBnYI"},"source":["# function to train the model\r\n","def train():\r\n","    model.train()\r\n","\r\n","    total_loss, total_accuracy = 0, 0\r\n","  \r\n","    # empty list to save model predictions\r\n","    total_preds=[]\r\n","    total_labels =[]\r\n","  \r\n","    # iterate over batches\r\n","    for step,batch in enumerate(train_dataloader):\r\n","    \r\n","        # progress update after every 50 batches.\r\n","        if step % 100 == 0 and not step == 0:\r\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\r\n","\r\n","        # push the batch to gpu\r\n","        batch = [r.to(device) for r in batch]\r\n","\r\n","        sent_id, mask, labels = batch\r\n","\r\n","        # clear previously calculated gradients \r\n","        model.zero_grad()        \r\n","\r\n","        # get model predictions for the current batch\r\n","        preds = model(sent_id, mask)\r\n","\r\n","        # compute the loss between actual and predicted values\r\n","        loss = cross_entropy(preds, labels)\r\n","\r\n","        # add on to the total loss\r\n","        total_loss = total_loss + loss.item()\r\n","\r\n","        # backward pass to calculate the gradients\r\n","        loss.backward()\r\n","\r\n","        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\r\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","\r\n","        # update parameters\r\n","        optimizer.step()\r\n","\r\n","        # model predictions are stored on GPU. So, push it to CPU\r\n","        preds = preds.detach().cpu().numpy()\r\n","        preds = np.argmax(preds, axis=1)\r\n","        # append the model predictions\r\n","        total_preds+=list(preds)\r\n","        total_labels+=labels.tolist()\r\n","\r\n","    # compute the training loss of the epoch\r\n","    avg_loss = total_loss / len(train_dataloader)\r\n","\r\n","    # predictions are in the form of (no. of batches, size of batch, no. of classes).\r\n","    # reshape the predictions in form of (number of samples, no. of classes)\r\n","    #total_preds  = np.concatenate(total_preds, axis=0)\r\n","    f1 = f1_score(total_labels, total_preds, average='weighted')\r\n","    #returns the loss and predictions\r\n","    return avg_loss, f1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W2YqVCf2BnWC"},"source":["# function for evaluating the model\r\n","def evaluate():\r\n","  \r\n","    print(\"\\nEvaluating...\")\r\n","\r\n","    # deactivate dropout layers\r\n","    model.eval()\r\n","\r\n","    total_loss, total_accuracy = 0, 0\r\n","\r\n","    # empty list to save the model predictions\r\n","    total_preds = []\r\n","    total_labels = []\r\n","    # iterate over batches\r\n","    for step,batch in enumerate(val_dataloader):\r\n","    \r\n","        # Progress update every 50 batches.\r\n","        if step % 50 == 0 and not step == 0:\r\n","\r\n","          # Calculate elapsed time in minutes.\r\n","          #elapsed = format_time(time.time() - t0)\r\n","\r\n","          # Report progress.\r\n","          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\r\n","\r\n","        # push the batch to gpu\r\n","        batch = [t.to(device) for t in batch]\r\n","\r\n","        sent_id, mask, labels = batch\r\n","\r\n","        # deactivate autograd\r\n","        with torch.no_grad():\r\n","\r\n","            # model predictions\r\n","            preds = model(sent_id, mask)\r\n","\r\n","            # compute the validation loss between actual and predicted values\r\n","            loss = cross_entropy(preds,labels)\r\n","\r\n","            total_loss = total_loss + loss.item()\r\n","\r\n","            preds = preds.detach().cpu().numpy()\r\n","            preds = np.argmax(preds, axis=1)\r\n","            total_preds+=list(preds)\r\n","            total_labels+=labels.tolist()\r\n","    # compute the validation loss of the epoch\r\n","    avg_loss = total_loss / len(val_dataloader) \r\n","\r\n","    # reshape the predictions in form of (number of samples, no. of classes)\r\n","    #total_preds  = np.concatenate(total_preds, axis=0)\r\n","    \r\n","    f1 = f1_score(total_labels, total_preds, average='weighted')\r\n","    return avg_loss, f1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fe0K6wptBnUF"},"source":["def save_checkpoint(filename, epoch, model, optimizer, label_map, id2label):\r\n","    state = {\r\n","        'epoch': epoch,\r\n","        'model': model,\r\n","        'optimizer': optimizer,\r\n","        'label_map': label_map,\r\n","        'id_map':id2label}\r\n","    torch.save(state, filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wl69CDIeBnSF","executionInfo":{"status":"ok","timestamp":1615548351268,"user_tz":-60,"elapsed":305298,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"0089ae99-7f15-456e-a443-48ffb36868bf"},"source":["# set initial loss to infinite\r\n","best_valid_loss = float('inf')\r\n","\r\n","# empty lists to store training and validation loss of each epoch\r\n","train_losses=[]\r\n","valid_losses=[]\r\n","\r\n","#for each epoch\r\n","for epoch in range(epochs):\r\n","     \r\n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\r\n","    \r\n","    #train model\r\n","    train_loss, f1_train = train()\r\n","    \r\n","    #evaluate model\r\n","    valid_loss, f1_valid = evaluate()\r\n","    \r\n","    #save the best model\r\n","    if valid_loss < best_valid_loss:\r\n","        best_valid_loss = valid_loss\r\n","        file_name = 'topic_saved_weights.pt'\r\n","        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\r\n","    \r\n","    # append training and validation loss\r\n","    train_losses.append(train_loss)\r\n","    valid_losses.append(valid_loss)\r\n","    \r\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\r\n","    print(f'Validation Loss: {valid_loss:.3f}')\r\n","    print(f'\\nTraining F1: {f1_train:.3f}')\r\n","    print(f'Validation F1: {f1_valid:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Epoch 1 / 50\n","\n","Evaluating...\n","\n","Training Loss: 1.368\n","Validation Loss: 1.250\n","\n","Training F1: 0.315\n","Validation F1: 0.422\n","\n"," Epoch 2 / 50\n","\n","Evaluating...\n","\n","Training Loss: 1.265\n","Validation Loss: 1.157\n","\n","Training F1: 0.404\n","Validation F1: 0.366\n","\n"," Epoch 3 / 50\n","\n","Evaluating...\n","\n","Training Loss: 1.174\n","Validation Loss: 1.080\n","\n","Training F1: 0.486\n","Validation F1: 0.436\n","\n"," Epoch 4 / 50\n","\n","Evaluating...\n","\n","Training Loss: 1.147\n","Validation Loss: 1.066\n","\n","Training F1: 0.475\n","Validation F1: 0.369\n","\n"," Epoch 5 / 50\n","\n","Evaluating...\n","\n","Training Loss: 1.058\n","Validation Loss: 0.991\n","\n","Training F1: 0.521\n","Validation F1: 0.546\n","\n"," Epoch 6 / 50\n","\n","Evaluating...\n","\n","Training Loss: 1.090\n","Validation Loss: 0.975\n","\n","Training F1: 0.531\n","Validation F1: 0.578\n","\n"," Epoch 7 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.997\n","Validation Loss: 0.887\n","\n","Training F1: 0.575\n","Validation F1: 0.616\n","\n"," Epoch 8 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.963\n","Validation Loss: 0.893\n","\n","Training F1: 0.558\n","Validation F1: 0.634\n","\n"," Epoch 9 / 50\n","\n","Evaluating...\n","\n","Training Loss: 1.006\n","Validation Loss: 0.942\n","\n","Training F1: 0.520\n","Validation F1: 0.491\n","\n"," Epoch 10 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.925\n","Validation Loss: 0.848\n","\n","Training F1: 0.566\n","Validation F1: 0.638\n","\n"," Epoch 11 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.917\n","Validation Loss: 0.800\n","\n","Training F1: 0.561\n","Validation F1: 0.658\n","\n"," Epoch 12 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.843\n","Validation Loss: 0.774\n","\n","Training F1: 0.630\n","Validation F1: 0.681\n","\n"," Epoch 13 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.812\n","Validation Loss: 0.799\n","\n","Training F1: 0.677\n","Validation F1: 0.646\n","\n"," Epoch 14 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.849\n","Validation Loss: 0.779\n","\n","Training F1: 0.601\n","Validation F1: 0.657\n","\n"," Epoch 15 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.881\n","Validation Loss: 0.749\n","\n","Training F1: 0.598\n","Validation F1: 0.645\n","\n"," Epoch 16 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.844\n","Validation Loss: 0.779\n","\n","Training F1: 0.621\n","Validation F1: 0.677\n","\n"," Epoch 17 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.798\n","Validation Loss: 0.721\n","\n","Training F1: 0.654\n","Validation F1: 0.726\n","\n"," Epoch 18 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.802\n","Validation Loss: 0.778\n","\n","Training F1: 0.653\n","Validation F1: 0.680\n","\n"," Epoch 19 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.850\n","Validation Loss: 0.851\n","\n","Training F1: 0.618\n","Validation F1: 0.675\n","\n"," Epoch 20 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.845\n","Validation Loss: 0.698\n","\n","Training F1: 0.602\n","Validation F1: 0.714\n","\n"," Epoch 21 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.763\n","Validation Loss: 0.774\n","\n","Training F1: 0.673\n","Validation F1: 0.670\n","\n"," Epoch 22 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.763\n","Validation Loss: 0.808\n","\n","Training F1: 0.653\n","Validation F1: 0.724\n","\n"," Epoch 23 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.742\n","Validation Loss: 0.711\n","\n","Training F1: 0.681\n","Validation F1: 0.697\n","\n"," Epoch 24 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.733\n","Validation Loss: 0.712\n","\n","Training F1: 0.683\n","Validation F1: 0.689\n","\n"," Epoch 25 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.794\n","Validation Loss: 0.816\n","\n","Training F1: 0.649\n","Validation F1: 0.736\n","\n"," Epoch 26 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.766\n","Validation Loss: 0.704\n","\n","Training F1: 0.689\n","Validation F1: 0.702\n","\n"," Epoch 27 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.757\n","Validation Loss: 0.709\n","\n","Training F1: 0.660\n","Validation F1: 0.721\n","\n"," Epoch 28 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.730\n","Validation Loss: 0.845\n","\n","Training F1: 0.675\n","Validation F1: 0.709\n","\n"," Epoch 29 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.748\n","Validation Loss: 0.796\n","\n","Training F1: 0.670\n","Validation F1: 0.668\n","\n"," Epoch 30 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.908\n","Validation Loss: 0.784\n","\n","Training F1: 0.626\n","Validation F1: 0.666\n","\n"," Epoch 31 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.813\n","Validation Loss: 0.718\n","\n","Training F1: 0.600\n","Validation F1: 0.735\n","\n"," Epoch 32 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.779\n","Validation Loss: 0.669\n","\n","Training F1: 0.655\n","Validation F1: 0.747\n","\n"," Epoch 33 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.740\n","Validation Loss: 0.693\n","\n","Training F1: 0.678\n","Validation F1: 0.666\n","\n"," Epoch 34 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.690\n","Validation Loss: 0.674\n","\n","Training F1: 0.689\n","Validation F1: 0.718\n","\n"," Epoch 35 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.755\n","Validation Loss: 0.723\n","\n","Training F1: 0.680\n","Validation F1: 0.764\n","\n"," Epoch 36 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.742\n","Validation Loss: 0.721\n","\n","Training F1: 0.665\n","Validation F1: 0.708\n","\n"," Epoch 37 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.740\n","Validation Loss: 0.692\n","\n","Training F1: 0.700\n","Validation F1: 0.661\n","\n"," Epoch 38 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.738\n","Validation Loss: 0.683\n","\n","Training F1: 0.702\n","Validation F1: 0.738\n","\n"," Epoch 39 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.694\n","Validation Loss: 0.726\n","\n","Training F1: 0.704\n","Validation F1: 0.653\n","\n"," Epoch 40 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.639\n","Validation Loss: 0.676\n","\n","Training F1: 0.737\n","Validation F1: 0.716\n","\n"," Epoch 41 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.740\n","Validation Loss: 0.675\n","\n","Training F1: 0.690\n","Validation F1: 0.774\n","\n"," Epoch 42 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.689\n","Validation Loss: 0.637\n","\n","Training F1: 0.700\n","Validation F1: 0.790\n","\n"," Epoch 43 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.681\n","Validation Loss: 0.625\n","\n","Training F1: 0.690\n","Validation F1: 0.781\n","\n"," Epoch 44 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.713\n","Validation Loss: 0.662\n","\n","Training F1: 0.702\n","Validation F1: 0.746\n","\n"," Epoch 45 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.721\n","Validation Loss: 0.685\n","\n","Training F1: 0.695\n","Validation F1: 0.734\n","\n"," Epoch 46 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.702\n","Validation Loss: 0.668\n","\n","Training F1: 0.693\n","Validation F1: 0.737\n","\n"," Epoch 47 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.709\n","Validation Loss: 0.636\n","\n","Training F1: 0.676\n","Validation F1: 0.762\n","\n"," Epoch 48 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.643\n","Validation Loss: 0.727\n","\n","Training F1: 0.732\n","Validation F1: 0.696\n","\n"," Epoch 49 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.699\n","Validation Loss: 0.689\n","\n","Training F1: 0.727\n","Validation F1: 0.767\n","\n"," Epoch 50 / 50\n","\n","Evaluating...\n","\n","Training Loss: 0.705\n","Validation Loss: 0.744\n","\n","Training F1: 0.710\n","Validation F1: 0.668\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ffhs2wKBnQH","executionInfo":{"status":"ok","timestamp":1615548359034,"user_tz":-60,"elapsed":313049,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"45c847cc-beb2-4864-f047-f6b9b0e0c99a"},"source":["path = 'topic_saved_weights.pt'\r\n","test_df = ld.validation_data_frame\r\n","\r\n","checkpoint = torch.load(path,map_location=device)\r\n","model = checkpoint.get(\"model\")\r\n","\r\n","tokenizer = BertTokenizer.from_pretrained(berts[language])\r\n","\r\n","# weights_path = os.path.join(data_dir,\"Weights\",\"topic_saved_weights.pt\")\r\n","!cp topic_saved_weights.pt /content/drive/My\\ Drive/Tesi/Code/Intent_Classification/Weights\r\n","\r\n","# tokenize and encode sequences in the test set\r\n","test_text,test_labels = test_df[\"query\"],test_df[\"category\"]\r\n","\r\n","tokens_test = tokenizer.batch_encode_plus(\r\n","    test_text.tolist(),\r\n","    max_length = max_seq_len,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False\r\n",")\r\n","\r\n","# for test set\r\n","test_seq = torch.tensor(tokens_test['input_ids'])\r\n","test_mask = torch.tensor(tokens_test['attention_mask'])\r\n","test_y = torch.tensor(test_labels.tolist())\r\n","print(\"test_y:\",test_y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test_y: tensor([2, 2, 3, 2, 0, 0, 2, 2, 2, 3, 1, 2, 0, 2, 1, 2, 2, 2, 0, 2, 2, 0, 1, 3,\n","        2, 1, 0, 1, 1, 0, 2, 2, 3, 2, 0, 3, 1, 1, 0, 3, 2, 0, 1, 2, 3, 3, 3, 1,\n","        3, 1, 1, 3, 2, 0, 3, 0, 3, 0, 1, 2, 2, 0, 2, 1, 0, 2, 3, 1, 2, 2, 3, 2,\n","        2, 2, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OVVuj22DBnN4"},"source":["# get predictions for test data\r\n","with torch.no_grad():\r\n","    preds = model(test_seq.to(device), test_mask.to(device))\r\n","    preds = preds.detach().cpu().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOcGUj_qBnLr","executionInfo":{"status":"ok","timestamp":1615548359036,"user_tz":-60,"elapsed":313032,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"bacc204a-6fe9-4b85-994b-817c249a7e89"},"source":["preds = np.argmax(preds, axis = 1)\r\n","print(classification_report(test_y, preds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.92      0.80      0.86        15\n","           1       1.00      0.73      0.85        15\n","           2       0.81      1.00      0.90        30\n","           3       1.00      0.93      0.97        15\n","\n","    accuracy                           0.89        75\n","   macro avg       0.93      0.87      0.89        75\n","weighted avg       0.91      0.89      0.89        75\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ou9Wb49hB5Zj"},"source":["class Prediction:\r\n","    def __init__(self):\r\n","        path = 'topic_saved_weights.pt'\r\n","\r\n","        checkpoint = torch.load(path,map_location=device)\r\n","        self.predictor = checkpoint.get(\"model\")\r\n","        self.tokenizer = BertTokenizer.from_pretrained(berts[language])\r\n","        self.tag = checkpoint.get(\"id_map\")\r\n","\r\n","    def predict(self,text):\r\n","        tokens = self.tokenizer.tokenize(text)\r\n","        tokens = tokens[:max_seq_len - 2]\r\n","        tokens = ['[CLS]'] + tokens + ['[SEP]']\r\n","\r\n","        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\r\n","        input_ids = input_ids + [0] * (max_seq_len-len(input_ids))\r\n","        input_ids = torch.tensor(input_ids).unsqueeze(0)\r\n","        input_ids = input_ids.to(device)\r\n","\r\n","        input_mask = [1]*len(tokens) + [0] * (max_seq_len - len(tokens))\r\n","        input_mask = torch.tensor(input_mask).unsqueeze(0)\r\n","        input_mask = input_mask.to(device)\r\n","\r\n","        logits = self.predictor(input_ids,input_mask)\r\n","        prob = torch.nn.functional.softmax(logits,dim=1)\r\n","        result = [(self.tag[idx],item *100) for idx,item in enumerate(prob[0].tolist())]\r\n","        preds = logits.detach().cpu().numpy()\r\n","        pred_val = np.argmax(preds)\r\n","        pred_val = self.tag[pred_val]\r\n","        return result,pred_val\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GrC10gQtB5W1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615550013044,"user_tz":-60,"elapsed":1551,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"cfd4becb-fb4c-49a0-98e1-ee42715151d5"},"source":["pred = Prediction()\r\n","\r\n","print(max_seq_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dGuWxJXB5Tz","executionInfo":{"status":"ok","timestamp":1615548923865,"user_tz":-60,"elapsed":937,"user":{"displayName":"Davide Iraci","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEZfBIJCY52WxLY0E2IrD9frPLvSBomnnkEYUUvA=s64","userId":"18223997902854243280"}},"outputId":"b83d5b7a-9940-4a41-c6ca-8eaae67322d3"},"source":["list_input = [\r\n","     'di che colore è',\r\n","     'che tessitura ha questo oggetto',\r\n","     'che cosa è questo',\r\n","     'che forma ha',\r\n","     'cosa è',\r\n","     'è un toroide'] \r\n","\r\n","for item in list_input:\r\n","    confidence,pred_val = pred.predict(item)\r\n","    prob = round([i for i in confidence if i[0]==pred_val][0][1],4)\r\n","    print(\"'\" + item + \"' = \" + pred_val + \": \" + str(prob))\r\n","    print([(i[0],round(i[1],4)) for i in confidence])\r\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["'di che colore è' = color_query: 98.0531\n","[('texture_query', 0.4333), ('shape_query', 1.4912), ('general_query', 0.0224), ('color_query', 98.0531)]\n","\n","'che tessitura ha questo oggetto' = texture_query: 75.0615\n","[('texture_query', 75.0615), ('shape_query', 5.4596), ('general_query', 4.389), ('color_query', 15.09)]\n","\n","'che cosa è questo' = general_query: 98.7136\n","[('texture_query', 1.1098), ('shape_query', 0.0995), ('general_query', 98.7136), ('color_query', 0.0771)]\n","\n","'che forma ha' = shape_query: 99.5111\n","[('texture_query', 0.2635), ('shape_query', 99.5111), ('general_query', 0.1109), ('color_query', 0.1145)]\n","\n","'cosa è' = general_query: 98.968\n","[('texture_query', 0.9201), ('shape_query', 0.0265), ('general_query', 98.968), ('color_query', 0.0854)]\n","\n","'è un toroide' = shape_query: 97.1035\n","[('texture_query', 0.9285), ('shape_query', 97.1035), ('general_query', 0.2618), ('color_query', 1.7062)]\n","\n"],"name":"stdout"}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object_classification_Random_Forest.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python394jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49","display_name":"Python 3.9.4 64-bit"},"language_info":{"name":"python","version":"3.9.4"},"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"cells":[{"cell_type":"markdown","metadata":{"id":"cS5bAg4ZXG0A"},"source":["# Object classification"]},{"cell_type":"code","metadata":{"id":"AlJYWzcwWeaP"},"source":["from sklearn.linear_model import SGDClassifier \n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import os\n","import ast\n","from glob import glob\n","import random\n","import traceback\n","from tabulate import tabulate\n","import pickle\n","\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P_IMy8DyEf4u"},"source":["## Parameters"]},{"cell_type":"code","metadata":{"id":"qGY0uJJWEkKt"},"source":["new_data=True\n","load_old_params=True\n","save_params=False\n","selected_space=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpkLZXjuAefH"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vftXx2KeZIBe"},"source":["## Utils functions"]},{"cell_type":"code","metadata":{"id":"XB20DvoUZK0B"},"source":["def translate(name):\n","    translate_dict={\"apple\":\"mela\",\n","                    \"ball\":\"palla\",\n","                    \"bell pepper\":\"peperone\",\n","                    \"binder\":\"raccoglitore\",\n","                    \"bowl\":\"ciotola\",\n","                    \"calculator\":\"calcolatrice\",\n","                    \"camera\":\"fotocamera\",\n","                    \"cell phone\":\"telefono\",\n","                    \"cereal box\":\"scatola\",\n","                    \"coffee mug\":\"tazza\",\n","                    \"comb\":\"spazzola\",\n","                    \"dry battery\":\"batteria\",\n","                    \"flashlight\":\"torcia\",\n","                    \"food box\":\"scatola\",\n","                    \"food can\":\"lattina\",\n","                    \"food cup\":\"barattolo\",\n","                    \"food jar\":\"barattolo\",\n","                    \"garlic\":\"aglio\",\n","                    \"lemon\":\"limone\",\n","                    \"lime\":\"lime\",\n","                    \"onion\":\"cipolla\",\n","                    \"orange\":\"arancia\",\n","                    \"peach\":\"pesca\",\n","                    \"pear\":\"pera\",\n","                    \"potato\":\"patata\",\n","                    \"tomato\":\"pomodoro\",\n","                    \"soda can\":\"lattina\",\n","                    \"marker\":\"pennarello\",\n","                    \"plate\":\"piatto\",\n","                    \"notebook\":\"quaderno\",\n","                    \"keyboard\":\"tastiera\",\n","                    \"glue stick\":\"colla\",\n","                    \"sponge\":\"spugna\",\n","                    \"toothpaste\":\"dentifricio\",\n","                    \"toothbrush\":\"spazzolino\"\n","                    }\n","    try:\n","        return translate_dict[name]\n","    except:\n","        return name\n","\n","def normalize_color(color):\n","    return color\n","    color_normalized=[]\n","    for i,f in enumerate(color):\n","        if i%3==0:\n","            color_normalized.append(f/256)\n","        else:\n","            color_normalized.append((f+128)/256)\n","    return color_normalized\n","\n","\n","def sort_and_cut_dict(dictionary,limit=3):\n","    iterator=sorted(dictionary.items(), key=lambda item: item[1], reverse=True)[:limit]\n","    coef=sum([i[1] for i in iterator])\n","    return {k: v/coef for k, v in iterator}            \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"scbuiqcaXuQ0"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"wv0tifnuXkIw","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e710ac11-d078-4a35-c131-1593e46466a2"},"source":["obj_dir = \"/content/drive/My Drive/Tesi/Code/Object_classification\"\n","#obj_dir = \"/Users/marco/Google Drive/Tesi/Code/Object_classification\"\n","data_dir = obj_dir+\"/Data\"\n","model_filename = obj_dir+\"/model.pkl\"\n","exclusion_list=[\"binder\",\"camera\",\"cell phone\",\"dry battery\"]\n","test_folder=[\"apple_3\",\n","             \"bell_pepper_1\",\n","             \"bowl_3\",\n","             \"cereal_box_1\",\n","             \"coffe_mug_5\",\n","             \"comb_5\",\n","             \"flashlight_4\",\n","             \"food_box_6\",\n","             \"food_can_2\",\n","             \"garlic_1\",\n","             \"glue_stick_3\",\n","             \"keyboard_2\",\n","             \"lemon_1\",\n","             \"lime_1\",\n","             \"onion_1\",\n","             \"orange_1\",\n","             \"pear_4\",\n","             \"plate_5\",\n","             \"potato_5\",\n","             \"soda_can_2\",\n","             \"sponge_8\",\n","             \"tomato_1\",\n","             \"toothbrush_2\"\n","             ]\n","if new_data:\n","    color_train=[]\n","    shape_train=[]\n","    texture_train=[]\n","    color_test=[]\n","    shape_test=[]\n","    texture_test=[]\n","    y_train=[]\n","    y_test=[]\n","    file_list=glob(data_dir+'/**', recursive=True)\n","    number_of_files=len(file_list)\n","    with open(obj_dir+\"/dictionary.pickle\",\"rb\") as f:\n","        dictionary=pickle.load(f)\n","        for j,filename in enumerate(file_list):\n","            if os.path.isfile(filename) and filename.endswith(\".txt\"):\n","                print(\"{:.2f}%\".format(j*100/number_of_files))\n","                name=\" \".join(filename.split(\"_\")[:-3]).rsplit(\"/\", 1)[1]\n","                if name in exclusion_list:\n","                    continue\n","                name=translate(name)\n","                folder=filename.split(\"/\")[-2]\n","\n","                if folder not in dictionary.keys():\n","                    continue\n","                with open(filename, \"r\") as f:\n","                    features=[]\n","                    try:\n","                        lines=f.readlines()\n","                        for line in lines:\n","                            features.append(ast.literal_eval(line))\n","                        if len(features)==3:        \n","                            color,shape,texture=features\n","                            color=normalize_color(color)\n","                            if folder in test_folder:\n","                                color_test.append(color)\n","                                shape_test.append(shape)\n","                                texture_test.append(texture)\n","                                if selected_space:\n","                                    y_test.append(folder)\n","                                else:    \n","                                    y_test.append(name)\n","                            else:\n","                                color_train.append(color)\n","                                shape_train.append(shape)\n","                                texture_train.append(texture)    \n","                                if selected_space:\n","                                    y_train.append(folder)\n","                                else:    \n","                                    y_train.append(name)\n","                    except:\n","                        print(\"Error in {}\".format(filename))\n","                        continue    \n","        y_train=np.array(y_train)\n","        y_test=np.array(y_test)\n","        X_train=np.array([np.concatenate((c, s, t), axis=None) for c,s,t in zip(color_train,shape_train,texture_train)])\n","        X_test=np.array([np.concatenate((c, s, t), axis=None) for c,s,t in zip(color_test,shape_test,texture_test)]) \n","\n","        color_train=np.array(color_train)\n","        shape_train=np.array(shape_train)\n","        texture_train=np.array(texture_train)\n","        color_test=np.array(color_test)\n","        shape_test=np.array(shape_test)\n","        texture_test=np.array(texture_test)\n","        X_train=color_train\n","        X_test=color_test\n","            \n","    \n","else:\n","    X_train=np.load(obj_dir+\"/input_train.npy\")\n","    X_test=np.load(obj_dir+\"/input_test.npy\")\n","    color_train=np.load(obj_dir+\"/color_train.npy\")\n","    shape_train=np.load(obj_dir+\"/shape_train.npy\")\n","    texture_train=np.load(obj_dir+\"/texture_train.npy\")\n","    color_test=np.load(obj_dir+\"/color_test.npy\")\n","    shape_test=np.load(obj_dir+\"/shape_test.npy\")\n","    texture_test=np.load(obj_dir+\"/texture_test.npy\")\n","    y_train=np.load(obj_dir+\"/output_train.npy\") \n","    y_test=np.load(obj_dir+\"/output_test.npy\")   "],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.07%\n","0.07%\n","0.08%\n","0.09%\n","0.10%\n","0.10%\n","0.11%\n","0.12%\n","0.13%\n","0.13%\n","0.14%\n","0.15%\n","0.16%\n","0.16%\n","0.17%\n","0.18%\n","0.19%\n","0.19%\n","0.20%\n","0.21%\n","0.22%\n","0.22%\n","0.23%\n","0.24%\n","0.25%\n","0.25%\n","0.26%\n","0.27%\n","0.27%\n","0.28%\n","0.29%\n","0.30%\n","0.30%\n","0.31%\n","0.32%\n","0.33%\n","0.33%\n","0.34%\n","0.35%\n","0.36%\n","0.36%\n","0.37%\n","0.38%\n","0.39%\n","0.39%\n","0.40%\n","0.41%\n","0.42%\n","0.42%\n","0.43%\n","0.44%\n","0.45%\n","0.45%\n","0.46%\n","0.47%\n","0.48%\n","0.48%\n","0.49%\n","0.51%\n","0.51%\n","0.52%\n","0.53%\n","0.53%\n","0.54%\n","0.55%\n","0.56%\n","0.56%\n","0.57%\n","0.58%\n","0.59%\n","0.59%\n","0.60%\n","0.61%\n","0.62%\n","0.62%\n","0.63%\n","0.64%\n","0.65%\n","0.65%\n","0.66%\n","0.67%\n","0.68%\n","0.68%\n","0.69%\n","0.70%\n","0.71%\n","0.71%\n","0.72%\n","0.73%\n","0.74%\n","0.74%\n","0.75%\n","0.76%\n","0.77%\n","0.77%\n","0.78%\n","0.79%\n","0.79%\n","0.80%\n","0.81%\n","0.82%\n","0.82%\n","0.83%\n","0.84%\n","0.85%\n","0.85%\n","0.86%\n","0.87%\n","0.88%\n","0.88%\n","0.89%\n","0.90%\n","0.91%\n","0.91%\n","0.92%\n","0.94%\n","0.94%\n","0.95%\n","0.96%\n","0.97%\n","0.97%\n","0.98%\n","0.99%\n","1.00%\n","1.00%\n","1.01%\n","1.02%\n","1.03%\n","1.03%\n","1.04%\n","1.05%\n","1.05%\n","1.06%\n","1.07%\n","1.08%\n","1.08%\n","1.09%\n","1.10%\n","1.11%\n","1.11%\n","1.12%\n","1.13%\n","1.14%\n","1.14%\n","1.15%\n","1.16%\n","1.17%\n","1.17%\n","1.18%\n","1.19%\n","1.20%\n","1.20%\n","1.21%\n","1.22%\n","1.23%\n","1.23%\n","1.24%\n","1.25%\n","1.26%\n","1.26%\n","1.27%\n","1.28%\n","1.29%\n","1.29%\n","1.30%\n","1.31%\n","1.31%\n","1.32%\n","1.33%\n","1.34%\n","1.34%\n","1.35%\n","1.36%\n","1.37%\n","1.37%\n","1.39%\n","1.40%\n","1.40%\n","1.41%\n","1.42%\n","1.43%\n","1.43%\n","1.44%\n","1.45%\n","1.46%\n","1.46%\n","1.47%\n","1.48%\n","1.49%\n","1.49%\n","1.50%\n","1.51%\n","1.52%\n","1.52%\n","1.53%\n","1.54%\n","1.55%\n","1.55%\n","1.56%\n","1.57%\n","1.57%\n","1.58%\n","1.59%\n","1.60%\n","1.60%\n","1.61%\n","1.62%\n","1.63%\n","1.63%\n","1.64%\n","1.65%\n","1.66%\n","1.66%\n","1.67%\n","1.68%\n","1.69%\n","1.69%\n","1.70%\n","1.71%\n","1.72%\n","1.72%\n","1.73%\n","1.74%\n","1.75%\n","1.75%\n","1.76%\n","1.77%\n","1.78%\n","1.78%\n","1.79%\n","1.80%\n","1.81%\n","1.81%\n","1.82%\n","1.83%\n","1.83%\n","1.84%\n","1.85%\n","1.86%\n","1.86%\n","1.87%\n","1.88%\n","1.89%\n","1.89%\n","1.90%\n","1.91%\n","1.92%\n","1.92%\n","2.70%\n","2.71%\n","2.72%\n","2.73%\n","2.73%\n","2.74%\n","2.75%\n","2.76%\n","2.76%\n","2.77%\n","2.78%\n","2.79%\n","2.79%\n","2.80%\n","2.81%\n","2.82%\n","2.82%\n","2.83%\n","2.84%\n","2.85%\n","2.85%\n","2.86%\n","2.87%\n","2.87%\n","2.88%\n","2.89%\n","2.90%\n","2.90%\n","2.91%\n","2.92%\n","2.93%\n","2.93%\n","2.94%\n","2.95%\n","2.96%\n","2.96%\n","2.97%\n","2.98%\n","2.99%\n","2.99%\n","3.00%\n","3.01%\n","3.02%\n","3.02%\n","3.03%\n","3.04%\n","3.05%\n","3.05%\n","3.06%\n","3.07%\n","3.08%\n","3.08%\n","3.09%\n","3.10%\n","3.11%\n","3.11%\n","3.12%\n","3.13%\n","3.13%\n","3.14%\n","3.15%\n","3.16%\n","3.16%\n","3.17%\n","3.19%\n","3.19%\n","3.20%\n","3.21%\n","3.22%\n","3.22%\n","3.23%\n","3.24%\n","3.25%\n","3.25%\n","3.26%\n","3.27%\n","3.28%\n","3.28%\n","3.29%\n","3.30%\n","3.31%\n","3.31%\n","3.32%\n","3.33%\n","3.34%\n","3.34%\n","3.35%\n","3.36%\n","3.37%\n","3.37%\n","3.38%\n","3.39%\n","3.39%\n","3.40%\n","3.41%\n","3.42%\n","3.42%\n","3.43%\n","3.44%\n","3.45%\n","3.45%\n","3.46%\n","3.47%\n","3.48%\n","3.48%\n","3.49%\n","3.50%\n","3.51%\n","3.51%\n","3.52%\n","3.53%\n","3.54%\n","3.54%\n","3.55%\n","3.56%\n","3.57%\n","3.57%\n","3.58%\n","3.59%\n","3.60%\n","3.60%\n","3.61%\n","3.62%\n","3.63%\n","3.63%\n","3.64%\n","3.65%\n","3.66%\n","3.67%\n","3.68%\n","3.68%\n","3.69%\n","3.70%\n","3.71%\n","3.71%\n","3.72%\n","3.73%\n","3.74%\n","3.74%\n","3.75%\n","3.76%\n","3.77%\n","3.77%\n","3.78%\n","3.79%\n","3.80%\n","3.80%\n","3.81%\n","3.82%\n","3.83%\n","3.83%\n","3.84%\n","3.85%\n","3.86%\n","3.86%\n","3.87%\n","3.88%\n","3.89%\n","3.89%\n","3.90%\n","3.91%\n","3.91%\n","3.92%\n","3.93%\n","3.94%\n","3.94%\n","3.95%\n","3.96%\n","3.97%\n","3.97%\n","3.98%\n","3.99%\n","4.00%\n","4.00%\n","4.01%\n","4.02%\n","4.03%\n","4.03%\n","4.04%\n","4.05%\n","4.06%\n","4.06%\n","4.07%\n","4.08%\n","4.09%\n","4.09%\n","4.10%\n","4.11%\n","4.12%\n","4.13%\n","4.14%\n","4.15%\n","4.15%\n","4.16%\n","4.17%\n","4.17%\n","4.18%\n","4.19%\n","4.20%\n","4.20%\n","4.21%\n","4.22%\n","4.23%\n","4.23%\n","4.24%\n","4.25%\n","4.26%\n","4.26%\n","4.27%\n","4.28%\n","4.29%\n","4.29%\n","4.30%\n","4.31%\n","4.32%\n","4.32%\n","4.33%\n","4.34%\n","4.35%\n","4.35%\n","4.36%\n","4.37%\n","4.38%\n","4.38%\n","4.39%\n","4.40%\n","4.40%\n","4.41%\n","4.42%\n","4.43%\n","4.43%\n","4.44%\n","4.45%\n","4.46%\n","4.46%\n","4.47%\n","4.48%\n","4.49%\n","4.49%\n","4.50%\n","4.51%\n","4.52%\n","4.52%\n","4.53%\n","4.54%\n","4.55%\n","4.55%\n","4.56%\n","4.57%\n","4.58%\n","4.59%\n","4.60%\n","4.61%\n","4.61%\n","4.62%\n","4.63%\n","4.64%\n","4.64%\n","4.65%\n","4.66%\n","4.66%\n","4.67%\n","4.68%\n","4.69%\n","4.69%\n","4.70%\n","4.71%\n","4.72%\n","4.72%\n","4.73%\n","4.74%\n","4.75%\n","4.75%\n","4.76%\n","4.77%\n","4.78%\n","4.78%\n","4.79%\n","4.80%\n","4.81%\n","4.81%\n","4.82%\n","4.83%\n","4.84%\n","4.84%\n","4.85%\n","4.86%\n","4.87%\n","4.87%\n","4.88%\n","4.89%\n","4.90%\n","4.90%\n","4.91%\n","4.92%\n","4.92%\n","4.93%\n","4.94%\n","4.95%\n","4.95%\n","4.96%\n","4.97%\n","4.98%\n","4.98%\n","4.99%\n","5.00%\n","5.01%\n","5.01%\n","5.02%\n","5.03%\n","5.04%\n","5.04%\n","5.05%\n","5.06%\n","5.07%\n","5.07%\n","5.08%\n","5.10%\n","5.11%\n","5.12%\n","5.13%\n","5.13%\n","5.14%\n","5.15%\n","5.16%\n","5.16%\n","5.17%\n","5.18%\n","5.18%\n","5.19%\n","5.20%\n","5.21%\n","5.21%\n","5.22%\n","5.23%\n","5.24%\n","5.24%\n","5.25%\n","5.26%\n","5.27%\n","5.27%\n","5.28%\n","5.29%\n","5.30%\n","5.30%\n","5.31%\n","5.32%\n","5.33%\n","5.33%\n","5.34%\n","5.35%\n","5.36%\n","5.36%\n","5.37%\n","5.38%\n","5.39%\n","5.39%\n","5.40%\n","5.41%\n","5.42%\n","5.42%\n","5.43%\n","5.44%\n","5.44%\n","5.45%\n","5.46%\n","5.47%\n","5.47%\n","5.48%\n","5.50%\n","5.50%\n","5.51%\n","5.52%\n","5.53%\n","5.53%\n","5.54%\n","5.55%\n","5.56%\n","5.56%\n","5.57%\n","5.58%\n","5.59%\n","5.59%\n","5.60%\n","5.61%\n","5.62%\n","5.62%\n","5.63%\n","5.64%\n","5.65%\n","5.65%\n","5.66%\n","5.67%\n","5.68%\n","5.68%\n","5.69%\n","5.70%\n","5.70%\n","5.71%\n","5.72%\n","5.73%\n","5.73%\n","5.74%\n","5.75%\n","5.76%\n","5.76%\n","5.77%\n","5.78%\n","5.79%\n","5.79%\n","5.80%\n","5.81%\n","5.82%\n","5.82%\n","5.83%\n","5.84%\n","5.85%\n","5.85%\n","5.86%\n","5.87%\n","5.88%\n","5.88%\n","5.89%\n","5.90%\n","5.91%\n","5.91%\n","5.92%\n","5.93%\n","5.94%\n","5.94%\n","5.95%\n","5.96%\n","5.96%\n","5.97%\n","5.98%\n","5.99%\n","5.99%\n","6.00%\n","6.01%\n","6.02%\n","6.02%\n","6.03%\n","6.04%\n","6.05%\n","6.05%\n","6.06%\n","6.07%\n","6.08%\n","6.09%\n","6.10%\n","6.11%\n","6.11%\n","6.12%\n","6.13%\n","6.14%\n","6.14%\n","6.15%\n","6.16%\n","6.17%\n","6.17%\n","6.18%\n","6.19%\n","6.20%\n","6.20%\n","6.21%\n","6.22%\n","6.22%\n","6.23%\n","6.24%\n","6.25%\n","6.25%\n","6.26%\n","6.27%\n","6.28%\n","6.28%\n","6.29%\n","6.30%\n","6.31%\n","6.31%\n","6.32%\n","6.33%\n","6.34%\n","6.34%\n","6.35%\n","6.36%\n","6.37%\n","6.37%\n","6.38%\n","6.39%\n","6.40%\n","6.40%\n","6.41%\n","6.42%\n","6.43%\n","6.43%\n","6.44%\n","6.45%\n","6.46%\n","6.46%\n","6.47%\n","6.48%\n","6.48%\n","6.49%\n","6.50%\n","6.51%\n","6.52%\n","6.53%\n","6.54%\n","6.54%\n","6.55%\n","6.56%\n","6.57%\n","6.57%\n","6.58%\n","6.59%\n","6.60%\n","6.60%\n","6.61%\n","6.62%\n","6.63%\n","6.63%\n","6.64%\n","6.65%\n","6.66%\n","6.66%\n","6.67%\n","6.68%\n","6.69%\n","6.69%\n","6.70%\n","6.71%\n","6.72%\n","6.72%\n","6.73%\n","6.74%\n","6.74%\n","6.75%\n","6.76%\n","6.77%\n","6.77%\n","6.78%\n","6.79%\n","6.80%\n","6.80%\n","6.81%\n","6.82%\n","6.83%\n","6.83%\n","6.84%\n","6.85%\n","6.86%\n","6.86%\n","6.87%\n","6.88%\n","6.89%\n","6.89%\n","6.90%\n","6.91%\n","6.92%\n","6.92%\n","6.94%\n","6.95%\n","6.95%\n","6.96%\n","6.97%\n","6.98%\n","6.98%\n","6.99%\n","7.00%\n","7.00%\n","7.01%\n","7.02%\n","7.03%\n","7.03%\n","7.04%\n","7.05%\n","7.06%\n","7.06%\n","7.07%\n","7.08%\n","7.09%\n","7.09%\n","7.10%\n","7.11%\n","7.12%\n","7.12%\n","7.13%\n","7.14%\n","7.15%\n","7.15%\n","7.16%\n","7.17%\n","7.18%\n","7.18%\n","7.19%\n","7.20%\n","7.21%\n","7.21%\n","7.22%\n","7.23%\n","7.24%\n","7.24%\n","7.25%\n","7.26%\n","7.26%\n","7.27%\n","7.28%\n","7.29%\n","7.29%\n","7.30%\n","7.31%\n","7.32%\n","7.33%\n","7.34%\n","7.35%\n","7.35%\n","7.36%\n","7.37%\n","7.38%\n","7.38%\n","7.39%\n","7.40%\n","7.41%\n","7.41%\n","7.42%\n","7.43%\n","7.44%\n","7.44%\n","7.45%\n","7.46%\n","7.47%\n","7.47%\n","7.48%\n","7.49%\n","7.50%\n","7.50%\n","7.51%\n","7.52%\n","7.52%\n","7.53%\n","7.54%\n","7.55%\n","7.55%\n","7.56%\n","7.57%\n","7.58%\n","7.58%\n","7.59%\n","7.60%\n","7.61%\n","7.61%\n","7.62%\n","7.63%\n","7.64%\n","7.64%\n","7.65%\n","7.66%\n","7.67%\n","7.67%\n","7.68%\n","7.69%\n","7.70%\n","7.70%\n","7.71%\n","7.72%\n","7.73%\n","7.73%\n","7.74%\n","7.75%\n","7.76%\n","7.76%\n","7.77%\n","7.78%\n","7.78%\n","7.79%\n","7.80%\n","7.81%\n","7.81%\n","7.82%\n","7.83%\n","7.84%\n","7.84%\n","7.85%\n","7.86%\n","7.87%\n","7.87%\n","7.88%\n","7.89%\n","7.90%\n","7.90%\n","7.91%\n","7.92%\n","7.93%\n","7.93%\n","7.94%\n","7.95%\n","7.96%\n","7.96%\n","7.97%\n","7.98%\n","7.99%\n","7.99%\n","8.00%\n","8.01%\n","8.02%\n","8.02%\n","8.03%\n","8.04%\n","8.04%\n","8.05%\n","8.06%\n","8.07%\n","8.07%\n","8.08%\n","8.10%\n","8.11%\n","8.12%\n","8.13%\n","8.13%\n","8.14%\n","8.15%\n","8.16%\n","8.16%\n","8.17%\n","8.18%\n","8.19%\n","8.19%\n","8.20%\n","8.21%\n","8.22%\n","8.22%\n","8.23%\n","8.24%\n","8.25%\n","8.25%\n","8.26%\n","8.27%\n","8.28%\n","8.28%\n","8.29%\n","8.30%\n","8.30%\n","8.31%\n","8.32%\n","8.33%\n","8.33%\n","8.34%\n","8.35%\n","8.36%\n","8.36%\n","8.37%\n","8.38%\n","8.39%\n","8.39%\n","8.40%\n","8.41%\n","8.42%\n","8.42%\n","8.43%\n","8.44%\n","8.45%\n","8.46%\n","8.47%\n","8.48%\n","8.48%\n","8.49%\n","8.50%\n","8.51%\n","8.51%\n","8.52%\n","8.53%\n","8.54%\n","8.54%\n","8.55%\n","8.56%\n","8.56%\n","8.57%\n","8.58%\n","8.59%\n","8.59%\n","8.60%\n","8.61%\n","8.62%\n","8.62%\n","8.63%\n","8.64%\n","8.65%\n","8.65%\n","8.66%\n","8.67%\n","8.68%\n","8.68%\n","8.69%\n","8.70%\n","8.71%\n","8.71%\n","8.72%\n","8.73%\n","8.74%\n","8.74%\n","8.75%\n","8.76%\n","8.77%\n","8.77%\n","8.78%\n","8.79%\n","8.80%\n","8.80%\n","8.81%\n","8.82%\n","8.82%\n","8.83%\n","8.84%\n","8.85%\n","8.85%\n","8.86%\n","8.87%\n","8.88%\n","8.88%\n","8.89%\n","8.90%\n","8.91%\n","8.91%\n","8.92%\n","8.93%\n","8.94%\n","8.94%\n","8.95%\n","8.96%\n","8.97%\n","8.98%\n","8.99%\n","9.00%\n","9.00%\n","9.01%\n","9.02%\n","9.03%\n","9.03%\n","9.04%\n","9.05%\n","9.06%\n","9.06%\n","9.07%\n","9.08%\n","9.08%\n","9.09%\n","9.10%\n","9.11%\n","9.11%\n","9.12%\n","9.13%\n","9.14%\n","9.14%\n","9.15%\n","9.16%\n","9.17%\n","9.17%\n","9.18%\n","9.19%\n","9.20%\n","9.20%\n","9.21%\n","9.22%\n","9.23%\n","9.23%\n","9.24%\n","9.25%\n","9.26%\n","9.26%\n","9.27%\n","9.28%\n","9.29%\n","9.29%\n","9.30%\n","9.31%\n","9.32%\n","9.32%\n","9.33%\n","9.34%\n","9.34%\n","9.35%\n","9.36%\n","9.37%\n","9.37%\n","9.38%\n","9.40%\n","9.40%\n","9.41%\n","9.42%\n","9.43%\n","9.43%\n","9.44%\n","9.45%\n","9.46%\n","9.46%\n","9.47%\n","9.48%\n","9.49%\n","9.49%\n","9.50%\n","9.51%\n","9.52%\n","9.52%\n","9.53%\n","9.54%\n","9.55%\n","9.55%\n","9.56%\n","9.57%\n","9.58%\n","9.58%\n","9.59%\n","9.60%\n","9.60%\n","9.61%\n","9.62%\n","9.63%\n","9.63%\n","9.64%\n","9.65%\n","9.66%\n","9.66%\n","9.67%\n","9.68%\n","9.69%\n","9.69%\n","9.70%\n","9.71%\n","9.72%\n","9.72%\n","9.73%\n","9.74%\n","9.75%\n","9.75%\n","9.77%\n","9.78%\n","9.78%\n","9.79%\n","9.80%\n","9.81%\n","9.81%\n","9.82%\n","9.83%\n","9.84%\n","9.84%\n","9.85%\n","9.86%\n","9.86%\n","9.87%\n","9.88%\n","9.89%\n","9.89%\n","9.90%\n","9.91%\n","9.92%\n","9.92%\n","9.93%\n","9.94%\n","9.95%\n","9.95%\n","9.96%\n","9.97%\n","9.98%\n","9.98%\n","9.99%\n","10.00%\n","10.01%\n","10.01%\n","10.02%\n","10.03%\n","10.04%\n","10.04%\n","10.05%\n","10.06%\n","10.07%\n","10.07%\n","10.08%\n","10.09%\n","10.10%\n","10.10%\n","10.11%\n","10.12%\n","10.12%\n","10.13%\n","10.14%\n","10.15%\n","10.15%\n","10.16%\n","10.17%\n","10.18%\n","10.18%\n","10.19%\n","10.21%\n","10.22%\n","10.23%\n","10.24%\n","10.24%\n","10.25%\n","10.26%\n","10.27%\n","10.27%\n","10.28%\n","10.29%\n","10.30%\n","10.30%\n","10.31%\n","10.32%\n","10.33%\n","10.33%\n","10.34%\n","10.35%\n","10.36%\n","10.36%\n","10.37%\n","10.38%\n","10.38%\n","10.39%\n","10.40%\n","10.41%\n","10.41%\n","10.42%\n","10.43%\n","10.44%\n","10.44%\n","10.45%\n","10.46%\n","10.47%\n","10.47%\n","10.48%\n","10.49%\n","10.50%\n","10.50%\n","10.51%\n","10.52%\n","10.53%\n","10.53%\n","10.54%\n","10.55%\n","10.56%\n","10.56%\n","10.57%\n","10.58%\n","10.59%\n","10.59%\n","10.60%\n","10.61%\n","10.62%\n","10.62%\n","10.63%\n","10.64%\n","10.64%\n","10.65%\n","10.66%\n","10.67%\n","10.67%\n","10.68%\n","10.70%\n","10.70%\n","10.71%\n","10.72%\n","10.73%\n","10.73%\n","10.74%\n","10.75%\n","10.76%\n","10.76%\n","10.77%\n","10.78%\n","10.79%\n","10.79%\n","10.80%\n","10.81%\n","10.82%\n","10.82%\n","10.83%\n","10.84%\n","10.85%\n","10.85%\n","10.86%\n","10.87%\n","10.88%\n","10.88%\n","10.89%\n","10.90%\n","10.90%\n","10.91%\n","10.92%\n","10.93%\n","10.93%\n","10.94%\n","10.95%\n","10.96%\n","10.96%\n","10.97%\n","10.98%\n","10.99%\n","10.99%\n","11.00%\n","11.01%\n","11.02%\n","11.02%\n","11.04%\n","11.05%\n","11.05%\n","11.06%\n","11.07%\n","11.08%\n","11.08%\n","11.09%\n","11.10%\n","11.11%\n","11.11%\n","11.12%\n","11.13%\n","11.14%\n","11.14%\n","11.15%\n","11.16%\n","11.16%\n","11.17%\n","11.18%\n","11.19%\n","11.19%\n","11.20%\n","11.21%\n","11.22%\n","11.22%\n","11.23%\n","11.24%\n","11.25%\n","11.25%\n","11.26%\n","11.27%\n","11.28%\n","11.28%\n","11.29%\n","11.30%\n","11.31%\n","11.31%\n","11.32%\n","11.33%\n","11.34%\n","11.34%\n","11.35%\n","11.36%\n","11.37%\n","11.37%\n","11.38%\n","11.39%\n","11.40%\n","11.40%\n","11.41%\n","11.42%\n","11.42%\n","11.43%\n","11.44%\n","11.45%\n","11.45%\n","11.46%\n","11.47%\n","11.48%\n","11.49%\n","11.50%\n","11.51%\n","11.51%\n","11.52%\n","11.53%\n","11.54%\n","11.54%\n","11.55%\n","11.56%\n","11.57%\n","11.57%\n","11.58%\n","11.59%\n","11.60%\n","11.60%\n","11.61%\n","11.62%\n","11.63%\n","11.63%\n","11.64%\n","11.65%\n","11.66%\n","11.66%\n","11.67%\n","11.68%\n","11.68%\n","11.69%\n","11.70%\n","11.71%\n","11.71%\n","11.72%\n","11.73%\n","11.74%\n","11.74%\n","11.75%\n","11.76%\n","11.77%\n","11.77%\n","11.78%\n","11.79%\n","11.80%\n","11.80%\n","11.81%\n","11.82%\n","11.83%\n","11.83%\n","11.84%\n","11.85%\n","11.86%\n","11.86%\n","11.87%\n","11.88%\n","11.89%\n","11.89%\n","11.90%\n","11.91%\n","11.92%\n","11.92%\n","11.93%\n","11.94%\n","11.94%\n","11.95%\n","11.96%\n","11.97%\n","11.97%\n","11.98%\n","11.99%\n","12.00%\n","12.00%\n","12.01%\n","12.02%\n","12.03%\n","12.03%\n","12.04%\n","12.05%\n","12.06%\n","12.06%\n","12.07%\n","12.08%\n","12.09%\n","12.09%\n","12.10%\n","12.11%\n","12.12%\n","12.13%\n","12.14%\n","12.15%\n","12.15%\n","12.16%\n","12.17%\n","12.18%\n","12.18%\n","12.19%\n","12.20%\n","12.20%\n","12.21%\n","12.22%\n","12.23%\n","12.23%\n","12.24%\n","12.25%\n","12.26%\n","12.26%\n","12.27%\n","12.28%\n","12.29%\n","12.29%\n","12.30%\n","12.31%\n","12.32%\n","12.32%\n","12.33%\n","12.34%\n","12.35%\n","12.35%\n","12.36%\n","12.37%\n","12.38%\n","12.38%\n","12.39%\n","12.40%\n","12.41%\n","12.41%\n","12.42%\n","12.43%\n","12.44%\n","12.44%\n","12.45%\n","12.46%\n","12.46%\n","12.47%\n","12.48%\n","12.49%\n","12.49%\n","12.50%\n","12.51%\n","12.52%\n","12.52%\n","12.53%\n","12.54%\n","12.55%\n","12.55%\n","12.56%\n","12.57%\n","12.58%\n","12.58%\n","12.59%\n","12.60%\n","12.61%\n","12.61%\n","12.62%\n","12.63%\n","12.64%\n","12.64%\n","12.65%\n","12.66%\n","12.67%\n","12.67%\n","12.68%\n","12.69%\n","12.69%\n","12.70%\n","12.71%\n","12.72%\n","12.72%\n","12.73%\n","12.74%\n","12.75%\n","12.75%\n","12.77%\n","12.78%\n","12.78%\n","12.79%\n","12.80%\n","12.81%\n","12.81%\n","12.82%\n","12.83%\n","12.84%\n","12.84%\n","12.85%\n","12.86%\n","12.87%\n","12.87%\n","12.88%\n","12.89%\n","12.90%\n","12.90%\n","12.91%\n","12.92%\n","12.93%\n","12.93%\n","12.94%\n","12.95%\n","12.95%\n","12.96%\n","12.97%\n","12.98%\n","12.98%\n","12.99%\n","13.00%\n","13.01%\n","13.01%\n","13.02%\n","13.03%\n","13.04%\n","13.04%\n","13.05%\n","13.06%\n","13.07%\n","13.07%\n","13.08%\n","13.09%\n","13.10%\n","13.10%\n","13.11%\n","13.12%\n","13.13%\n","13.13%\n","13.14%\n","13.15%\n","13.16%\n","13.16%\n","13.17%\n","13.18%\n","13.19%\n","13.19%\n","13.20%\n","13.21%\n","13.21%\n","13.22%\n","13.24%\n","13.24%\n","13.25%\n","13.26%\n","13.27%\n","13.27%\n","13.28%\n","13.29%\n","13.30%\n","13.30%\n","13.31%\n","13.32%\n","13.33%\n","13.33%\n","13.34%\n","13.35%\n","13.36%\n","13.36%\n","13.37%\n","13.38%\n","13.39%\n","13.39%\n","13.40%\n","13.41%\n","13.42%\n","13.42%\n","13.43%\n","13.44%\n","13.45%\n","13.45%\n","13.46%\n","13.47%\n","13.47%\n","13.48%\n","13.49%\n","13.50%\n","13.50%\n","13.51%\n","13.52%\n","13.53%\n","13.53%\n","13.54%\n","13.55%\n","13.56%\n","13.56%\n","13.57%\n","13.58%\n","13.59%\n","13.59%\n","13.60%\n","13.61%\n","13.62%\n","13.63%\n","13.64%\n","13.65%\n","13.65%\n","13.66%\n","13.67%\n","13.68%\n","13.68%\n","13.69%\n","13.70%\n","13.71%\n","13.71%\n","13.72%\n","13.73%\n","13.73%\n","13.74%\n","13.75%\n","13.76%\n","13.76%\n","13.77%\n","13.78%\n","13.79%\n","13.79%\n","13.80%\n","13.81%\n","13.82%\n","13.82%\n","13.83%\n","13.84%\n","13.85%\n","13.85%\n","13.86%\n","13.87%\n","13.88%\n","13.88%\n","13.89%\n","13.90%\n","13.91%\n","13.91%\n","13.92%\n","13.93%\n","13.94%\n","13.94%\n","13.95%\n","13.96%\n","13.97%\n","13.97%\n","13.98%\n","13.99%\n","13.99%\n","14.00%\n","14.01%\n","14.02%\n","14.02%\n","14.03%\n","14.04%\n","14.05%\n","14.05%\n","14.11%\n","14.11%\n","14.12%\n","14.13%\n","14.14%\n","14.14%\n","14.15%\n","14.16%\n","14.17%\n","14.17%\n","14.18%\n","14.19%\n","14.20%\n","14.20%\n","14.21%\n","14.22%\n","14.23%\n","14.23%\n","14.24%\n","14.25%\n","14.25%\n","14.26%\n","14.27%\n","14.28%\n","14.28%\n","14.29%\n","14.30%\n","14.31%\n","14.31%\n","14.32%\n","14.33%\n","14.34%\n","14.34%\n","14.35%\n","14.36%\n","14.37%\n","14.37%\n","14.38%\n","14.39%\n","14.40%\n","14.40%\n","14.41%\n","14.42%\n","14.43%\n","14.43%\n","14.44%\n","14.45%\n","14.46%\n","14.46%\n","14.47%\n","14.48%\n","14.49%\n","14.49%\n","14.50%\n","14.51%\n","14.51%\n","14.52%\n","14.53%\n","14.54%\n","14.54%\n","14.55%\n","14.56%\n","14.57%\n","14.58%\n","14.59%\n","14.60%\n","14.60%\n","14.61%\n","14.62%\n","14.63%\n","14.63%\n","14.64%\n","14.65%\n","14.66%\n","14.66%\n","14.67%\n","14.68%\n","14.69%\n","14.69%\n","14.70%\n","14.71%\n","14.72%\n","14.72%\n","14.73%\n","14.74%\n","14.75%\n","14.75%\n","14.76%\n","14.77%\n","14.77%\n","14.78%\n","14.79%\n","14.80%\n","14.80%\n","14.81%\n","14.82%\n","14.83%\n","14.83%\n","14.84%\n","14.85%\n","14.86%\n","14.86%\n","14.87%\n","14.88%\n","14.89%\n","14.89%\n","14.90%\n","14.91%\n","14.92%\n","14.92%\n","14.93%\n","14.94%\n","14.95%\n","14.95%\n","14.96%\n","14.97%\n","14.98%\n","14.98%\n","14.99%\n","15.00%\n","15.01%\n","15.01%\n","15.02%\n","15.03%\n","15.03%\n","15.04%\n","15.06%\n","15.06%\n","15.07%\n","15.08%\n","15.09%\n","15.09%\n","15.10%\n","15.11%\n","15.12%\n","15.12%\n","15.13%\n","15.14%\n","15.15%\n","15.15%\n","15.16%\n","15.17%\n","15.18%\n","15.18%\n","15.19%\n","15.20%\n","15.21%\n","15.21%\n","15.22%\n","15.23%\n","15.24%\n","15.24%\n","15.25%\n","15.26%\n","15.27%\n","15.27%\n","15.28%\n","15.29%\n","15.29%\n","15.30%\n","15.31%\n","15.32%\n","15.32%\n","15.33%\n","15.34%\n","15.35%\n","15.35%\n","15.36%\n","15.37%\n","15.38%\n","15.38%\n","15.39%\n","15.41%\n","15.42%\n","15.43%\n","15.44%\n","15.44%\n","15.45%\n","15.46%\n","15.47%\n","15.47%\n","15.48%\n","15.49%\n","15.50%\n","15.50%\n","15.51%\n","15.52%\n","15.53%\n","15.53%\n","15.54%\n","15.55%\n","15.55%\n","15.56%\n","15.57%\n","15.58%\n","15.58%\n","15.59%\n","15.60%\n","15.61%\n","15.61%\n","15.62%\n","15.63%\n","15.64%\n","15.64%\n","15.65%\n","15.66%\n","15.67%\n","15.67%\n","15.68%\n","15.69%\n","15.70%\n","15.70%\n","15.71%\n","15.72%\n","15.73%\n","15.73%\n","15.74%\n","15.75%\n","15.76%\n","15.76%\n","15.77%\n","15.78%\n","15.79%\n","15.79%\n","15.80%\n","15.81%\n","15.81%\n","15.82%\n","15.84%\n","15.84%\n","15.85%\n","15.86%\n","15.87%\n","15.87%\n","15.88%\n","15.89%\n","15.90%\n","15.90%\n","15.91%\n","15.92%\n","15.93%\n","15.93%\n","15.94%\n","15.95%\n","15.96%\n","15.96%\n","15.97%\n","15.98%\n","15.99%\n","15.99%\n","16.00%\n","16.01%\n","16.02%\n","16.02%\n","16.03%\n","16.04%\n","16.05%\n","16.05%\n","16.06%\n","16.07%\n","16.07%\n","16.08%\n","16.09%\n","16.10%\n","16.10%\n","16.11%\n","16.12%\n","16.13%\n","16.13%\n","16.14%\n","16.15%\n","16.16%\n","16.16%\n","16.17%\n","16.18%\n","16.19%\n","16.19%\n","16.20%\n","Error in /content/drive/My Drive/Tesi/Code/Object_classification/Data/cereal_box/cereal_box_4/cereal_box_4_1_181.txt\n","16.21%\n","16.22%\n","16.22%\n","16.23%\n","16.24%\n","16.25%\n","16.25%\n","16.26%\n","16.27%\n","16.28%\n","16.29%\n","16.30%\n","16.31%\n","Error in /content/drive/My Drive/Tesi/Code/Object_classification/Data/cereal_box/cereal_box_5/cereal_box_5_4_25.txt\n","16.31%\n","16.32%\n","16.33%\n","16.33%\n","16.34%\n","16.35%\n","16.36%\n","16.36%\n","16.37%\n","16.38%\n","16.39%\n","16.39%\n","16.40%\n","16.41%\n","16.42%\n","16.42%\n","16.43%\n","16.44%\n","16.45%\n","16.45%\n","16.46%\n","16.47%\n","16.48%\n","16.48%\n","16.49%\n","16.50%\n","16.51%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cx7MrKhlMK48"},"source":["## Save input data"]},{"cell_type":"code","metadata":{"id":"jwlo3hjM9fTU"},"source":["if selected_space:\n","    new_y_train=[]    \n","    for i in y_train:\n","        new_label=dictionary[i][1]\n","        #new_label=new_label.split(\"-\")[0]\n","        new_y_train.append(new_label)\n","    new_y_test=[]    \n","    for i in y_test:\n","        new_label=dictionary[i][1]\n","        #new_label=new_label.split(\"-\")[0]\n","        new_y_test.append(new_label)\n","    y_train=np.array(new_y_train)\n","    y_test=np.array(new_y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AkQWcDhEMPHW"},"source":["if new_data and save_params:\n","    np.save(obj_dir+\"/input_train.npy\",X_train)\n","    np.save(obj_dir+\"/input_test.npy\",X_test)\n","    np.save(obj_dir+\"/color_train.npy\",color_train)\n","    np.save(obj_dir+\"/shape_train.npy\",shape_train)\n","    np.save(obj_dir+\"/texture_train.npy\",texture_train)\n","    np.save(obj_dir+\"/color_test.npy\",color_test)\n","    np.save(obj_dir+\"/shape_test.npy\",shape_test)\n","    np.save(obj_dir+\"/texture_test.npy\",texture_test)\n","    np.save(obj_dir+\"/output_test.npy\",y_test)\n","    np.save(obj_dir+\"/output_train.npy\",y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XKd6ZdrYroUs"},"source":["## Classifier fitting"]},{"cell_type":"code","metadata":{"id":"yu-53mHJrqYz"},"source":["if load_old_params and False:\n","    with open(model_filename, 'rb') as file:\n","        clf = pickle.load(file)\n","else:\n","    clf = RandomForestClassifier(n_jobs=-1, n_estimators=30)\n","    clf.fit(X_train,y_train)\n","    print(clf.score(X_test,y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f1lezuVZDRgv"},"source":["## Saving parameters"]},{"cell_type":"code","metadata":{"id":"rnnwu61qDYI2"},"source":["if save_params:\n","    with open(model_filename, 'wb') as file:\n","        pickle.dump(clf, file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jf_8o0CMrvqm"},"source":["## Score"]},{"cell_type":"code","metadata":{"id":"0Xxad1PrkV8z"},"source":["def classify_prediction(prediction):\n","    sure=[]\n","    unsure=[]\n","    dubious=[]\n","    cannot_answer=[]\n","    for pred in prediction:\n","        o,p=pred\n","        values=list(p.values())\n","        keys=list(p.keys())\n","        # sure\n","        if values[0]>0.8: \n","            sure.append(pred)\n","        # unsure        \n","        elif values[0]>0.6:\n","            unsure.append(pred)\n","        # dubious    \n","        elif values[0]>0.4:\n","            dubious.append(pred)\n","        # cannot_answer\n","        else:\n","            cannot_answer.append(pred)\n","    return {\"sure\":sure, \"unsure\":unsure, \"dubious\":dubious, \"cannot_answer\":cannot_answer}               \n","\n","def calculate_accuracy(category,prediction):\n","    counter=0\n","    if category==\"dubious\":\n","        for o,p in pred:\n","            if o in list(p.keys())[0:2]:\n","                counter+=1\n","    elif category==\"cannot_answer\":\n","        for o,p in pred:\n","            if o not in list(p.keys())[0:2]:\n","                counter+=1\n","    else:\n","        for o,p in pred:\n","            if o.split(\"-\")[0] in list(p.keys())[0]:\n","                counter+=1                       \n","    return counter/len(pred)            \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IlUhX4HJpChh","tags":[]},"source":["label_prob=clf.predict_proba(X_test)\n","pred=[[y_test[j],sort_and_cut_dict({clf.classes_[i]:v for i,v in enumerate(row)})] for j,row in enumerate(label_prob)]\n","pred_classified=classify_prediction(pred)\n","print(\"TOTAL TEST: {}\".format(len(pred)))\n","for l,pred in pred_classified.items():\n","    print(l.upper())\n","    print(40*\"-\")\n","    selected=[]\n","    for o,p in pred:\n","        if l==\"dubious\" and o not in list(p.keys())[0:2]:\n","            selected.append([o,\", \".join([str(a)+\":\"+str(round(b,2)) for a,b in list(p.items())])])\n","        elif l==\"cannot_answer\" and o in list(p.keys())[0:2]:\n","            selected.append([o,\", \".join([str(a)+\":\"+str(round(b,2)) for a,b in list(p.items())])])\n","\n","        elif l==\"unsure\" and o.split(\"-\")[0] not in list(p.keys())[0]:\n","            selected.append([o,\", \".join([str(a)+\":\"+str(round(b,2)) for a,b in list(p.items())])])\n","\n","        elif (l==\"sure\") and o != list(p.keys())[0]:\n","            selected.append([o,\", \".join([str(a)+\":\"+str(round(b,2)) for a,b in list(p.items())])])\n","    print(tabulate(selected, headers=['Original','Predicted']))\n","    print(\"Not correct: {}/{} - {:.2f}%\".format(len(selected),len(pred),len(selected)*100/len(pred)))\n","    accuracy=calculate_accuracy(l,pred)\n","    print(\"Accuracy: {:.2f}\".format(accuracy))    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i5BfEBPUNs3H"},"source":["## Test"]},{"cell_type":"code","metadata":{"id":"Yjz_XyvBccVf"},"source":["clf.score(X_test,y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GugKBF9pc4n-"},"source":["plt.plot(clf.feature_importances_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XyHwTYUO9fTY"},"source":["clf.feature_importances_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-K9I691s2PvE"},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","import pandas as pd\n","def classification_report(y_true, y_pred):\n","    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}.\")\n","    print(f\"Precision: {precision_score(y_true, y_pred, average='weighted', zero_division=True)}.\")\n","    print(f\"Recall: {recall_score(y_true, y_pred, average='weighted')}.\")\n","    print(f\"F1-Score: {f1_score(y_true, y_pred, average='weighted')}.\")\n","\n","    print(\"\\nSuddivisione per Classe\")\n","\n","    matrix = confusion_matrix(y_true, y_pred)\n","    # i falsi positivi si trovano sommando le colonne ed eliminando l'elemento diagonale (che rappresenta i veri positivi)\n","    FP = matrix.sum(axis=0) - np.diag(matrix)  \n","    # i falsi negativi invece si individuano sommando le righe\n","    FN = matrix.sum(axis=1) - np.diag(matrix)\n","    TP = np.diag(matrix)\n","    TN = matrix.sum() - (FP + FN + TP)\n","    class_names = np.unique(y_true)\n","    metrics_per_class = {}\n","    class_accuracies = (TP+TN)/(TP+TN+FP+FN)\n","    class_precisions = TP/(TP+FP)\n","    class_recalls = TP/(TP+FN)\n","    class_f1_scores = (2 * class_precisions * class_recalls) / (class_precisions + class_recalls)\n","    i=0\n","\n","    for name in class_names:\n","        metrics_per_class[name] = [class_accuracies.tolist().pop(i), class_precisions.tolist().pop(i), class_recalls.tolist().pop(i), class_f1_scores.tolist().pop(i), FP.tolist().pop(i), FN.tolist().pop(i)]\n","        i += 1\n","\n","    result = pd.DataFrame(metrics_per_class, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"FP\", \"FN\"]).transpose() \n","\n","    print(result, end=\"\\n\\n\")\n","    return metrics_per_class"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KtkyK3-9fTY"},"source":["#from sklearn.metrics import classification_report\n","y_true=y_test\n","y_pred=clf.predict(X_test)\n","d=classification_report(y_true, y_pred)\n","exclusion_list=[\"batteria\",\"ciotola\",\"piatto\",\"cipolla\",\"pomodoro\"]\n","for k in exclusion_list:\n","    del d[k]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BXm4-HB77G_K"},"source":["data=[]\n","labels = []\n","for k,v in d.items():\n","    data.append([k]+v[:4])\n","    labels.append(k)\n","data=np.array(data)\n","colors = ['red','yellow','blue','green']\n","df = pd.DataFrame(data.T, index=[\"Label\",\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]).transpose()\n","#df=df.set_index(\"Label\")\n","df[[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]]=df[[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]].apply(pd.to_numeric) \n","ax = df.plot(x=\"Label\", y=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"], kind=\"barh\",figsize=(15,15))\n","\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]}]}